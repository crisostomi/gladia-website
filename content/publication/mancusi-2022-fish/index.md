---
# Documentation: https://wowchemy.com/docs/managing-content/

title: 'Fish sounds: towards the evaluation of marine acoustic biodiversity through
  data-driven audio source separation'
subtitle: ''
summary: ''
authors:
- mancusi
- Nicola Zonca
- rodola
- Silvia Zuffi
tags: []
categories: []
date: '2022-01-01'
lastmod: 2023-02-05T10:57:36+01:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2023-02-05T09:57:35.321590Z'
publication_types:
- '2'
abstract: The marine ecosystem is changing at an alarming rate, exhibiting biodiversity
  loss and the migration of tropical species to temperate basins. Monitoring the underwater
  environments and their inhabitants is of fundamental importance to understand the
  evolution of these systems and implement safeguard policies. However, assessing
  and tracking biodiversity is often a complex task, especially in large and uncontrolled
  environments, such as the oceans. One of the most popular and effective methods
  for monitoring marine biodiversity is passive acoustics monitoring (PAM), which
  employs hydrophones to capture underwater sound. Many aquatic animals produce sounds
  characteristic of their own species; these signals travel efficiently underwater
  and can be detected even at great distances. Furthermore, modern technologies are
  becoming more and more convenient and precise, allowing for very accurate and careful
  data acquisition. To date, audio captured with PAM devices is frequently manually
  processed by marine biologists and interpreted with traditional signal processing
  techniques for the detection of animal vocalizations. This is a challenging task,
  as PAM recordings are often over long periods of time. Moreover, one of the causes
  of biodiversity loss is sound pollution; in data obtained from regions with loud
  anthropic noise, it is hard to separate the artificial from the fish sound manually.
  Nowadays, machine learning and, in particular, deep learning represents the state
  of the art for processing audio signals. Specifically, sound separation networks
  are able to identify and separate human voices and musical instruments. In this
  work, we show that the same techniques can be successfully used to automatically
  extract fish vocalizations in PAM recordings, opening up the possibility for biodiversity
  monitoring at a large scale.
publication: '*arXiv preprint arXiv:2201.05013*'
---
