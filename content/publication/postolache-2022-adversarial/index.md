---
# Documentation: https://wowchemy.com/docs/managing-content/

title: Adversarial Permutation Invariant Training for Universal Sound Separation
subtitle: ''
summary: ''
authors:
- postolache
- Jordi Pons
- Santiago Pascual
- Joan Serr√†
tags:
- Signal Processing
- Source Separation
categories: []
date: '2022-01-01'
lastmod: 2023-02-06T11:38:43+01:00
featured: false
draft: false
publication_short: "ICASSP 2023"
links:
- name: 'arXiv'
  url: https://arxiv.org/abs/2210.12108 

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2023-02-06T10:38:42.817844Z'
publication_types:
- '2'
abstract: 'Universal sound separation consists of separating mixes with arbitrary
  sounds of different types, and permutation invariant training (PIT) is used to train
  source agnostic models that do so. In this work, we complement PIT with adversarial
  losses but find it challenging with the standard formulation used in speech source
  separation. We overcome this challenge with a novel I-replacement context-based
  adversarial loss, and by training with multiple discriminators. Our experiments
  show that by simply improving the loss (keeping the same model and dataset) we obtain
  a non-negligible improvement of 1.4 dB SI-SNRi in the reverberant FUSS dataset.
  We also find adversarial PIT to be effective at reducing spectral holes, ubiquitous
  in mask-based separation models, which highlights the potential relevance of adversarial
  losses for source separation.'
publication: '*Proc. ICASSP*'
---
