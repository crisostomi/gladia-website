---
# Documentation: https://wowchemy.com/docs/managing-content/

title: 'Explanatory learning: Beyond empiricism in neural networks'
subtitle: ''
summary: 'When a ML system becomes an artificial scientist: mastering the game of Zendo with Transformers.'
authors:
- norelli
- mariani
- moschella
- santilli
- Giambattista Parascandolo
- melzi
- rodola
tags: []
categories: []
date: '2022-01-01'
lastmod: 2023-02-05T10:57:42+01:00
featured: false
draft: false
publication_short: "Preprint"

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2023-02-05T09:57:41.689990Z'
publication_types:
- '2'
abstract: At the crossroads of Program Synthesis and Meta-Learning, we introduce Explanatory
  Learning as the task of automatically discovering the symbolic explanation (PS)
  that enables few-shot sensible predictions on a novel environment given experience
  on other environments (M-L). Differently from PS, the program (explanation) interpreter
  in EL is not given and should be learned from a limited collection of associations
  explanation-observations. Unlike M-L, EL does not prescribe any adaptation at test
  time, seeking generalization in the broad meanings attributed to symbols by the
  learned interpreter. To exemplify the challenges of EL, we present the Odeen benchmark,
  which can also serve the PS and M-L paradigms. Finally, we introduce Critical Rationalist
  Networks, a deep learning approach to EL aligned with the Popperian view of knowledge
  acquisition. CRNs express several desired properties by construction; they are truly
  explainable, can adjust their processing at test-time for harder inferences, and
  can offer strong confidence guarantees on their predictions. Using Odeen as a testbed,
  we show how CRNs outperform empiricist end-to-end approaches of similar size and
  architecture (Transformers) in discovering explanations for unseen environments.

links:
- name: PDF
  url: https://arxiv.org/pdf/2201.10222.pdf
- icon: github
  icon_pack: fab
  name: 'GitHub'
  url: https://github.com/gladia-research-group/explanatory-learning
- name: arXiv
  url: https://arxiv.org/abs/2201.10222
- icon: twitter
  icon_pack: fab
  name: Thread
  url: https://twitter.com/noranta4/status/1493893787696906241?s=20
        
publication: '*arXiv preprint arXiv:2201.10222*'
---
